{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca2197-3a90-44d3-a133-4c2a5413df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Initialiser la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b37fb92-6f12-4531-bea6-80b7d02b5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472604a0-e105-4079-9552-d922437eafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du fichier CO2.csv (à adapter selon l'emplacement du fichier)\n",
    "path_co2 = 'CO2.csv'  # Assurez-vous que le fichier est dans le même répertoire ou indiquez le chemin absolu\n",
    "\n",
    "# Charger le fichier CSV\n",
    "CO2 = spark.read.csv(path_co2, header=True, inferSchema=True)\n",
    "\n",
    "# Afficher le schéma et un aperçu des données\n",
    "print(\"Schéma pour CO2:\")\n",
    "CO2.printSchema()\n",
    "CO2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6173e-faad-451a-8b59-8f90ae0e949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données\n",
    "# Liste des pays à inclure\n",
    "list_of_countries = [\n",
    "    \"United States\", \"China\", \"India\", \"Russia\", \"Germany\", \"France\",\n",
    "    \"United Kingdom\", \"Japan\", \"Canada\", \"Australia\"\n",
    "]\n",
    "\n",
    "# Colonnes à sélectionner\n",
    "columns_to_select = [\n",
    "    \"year\", \"country\", \"co2\", \"co2_per_capita\", \"population\",\n",
    "    \"gdp\", \"cement_co2\", \"coal_co2\", \"oil_co2\", \"share_global_co2\",\n",
    "]\n",
    "\n",
    "# Filtrer les données pour l'année >= 1880 et les pays dans la liste\n",
    "CO2_cleaned = CO2.filter((F.col(\"year\") >= 1880) & (F.col(\"country\").isin(list_of_countries)))\n",
    "\n",
    "# Sélectionner les colonnes pertinentes\n",
    "CO2_cleaned = CO2_cleaned.select(*columns_to_select)\n",
    "\n",
    "# Remplacer les valeurs nulles par 0\n",
    "CO2_cleaned = CO2_cleaned.fillna(0)\n",
    "\n",
    "# Convertir les colonnes numériques en DoubleType si nécessaire\n",
    "columns_to_cast = [\"co2\", \"co2_per_capita\", \"population\", \"gdp\", \"cement_co2\", \"coal_co2\", \"oil_co2\"]\n",
    "for col_name in columns_to_cast:\n",
    "    CO2_cleaned = CO2_cleaned.withColumn(col_name, F.col(col_name).cast(DoubleType()))\n",
    "\n",
    "# Vérification des valeurs nulles dans les colonnes après remplacement\n",
    "CO2_cleaned.select([F.count(F.col(c)).alias(c) for c in columns_to_select]).show()\n",
    "\n",
    "# Vérification et suppression des doublons\n",
    "CO2_cleaned = CO2_cleaned.dropDuplicates()\n",
    "\n",
    "# Renommer la colonne \"year\" en \"Year\"\n",
    "CO2_cleaned = CO2_cleaned.withColumnRenamed(\"year\", \"Year\")\n",
    "\n",
    "# Trier les données par année, puis par pays\n",
    "CO2_cleaned = CO2_cleaned.orderBy(F.col(\"Year\"), F.col(\"country\"))\n",
    "\n",
    "# Afficher les premières lignes pour vérifier le nettoyage\n",
    "CO2_cleaned.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9238226-d53f-46fb-8866-0c723b759ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temperature Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f5b25-a89d-471a-bb7a-67eaf7c9d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV\n",
    "path_tm = 'TM.csv'  # Remplacez par le chemin correct de votre fichier TM.csv\n",
    "TM = spark.read.csv(path_tm, header=True, inferSchema=True)\n",
    "\n",
    "# Afficher le schéma initial\n",
    "print(\"Schéma initial pour TM:\")\n",
    "TM.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c1b04-f17b-4077-839d-a8bee81621d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes des mois en DoubleType\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "for month in months:\n",
    "    TM = TM.withColumn(month, col(month).cast(DoubleType()))\n",
    "\n",
    "# Convertir la colonne 'DJF' en float et remplacer '***' par 0\n",
    "TM = TM.withColumn(\"DJF\", when(col(\"DJF\") == \"***\", 0).otherwise(col(\"DJF\").cast(\"float\")))\n",
    "\n",
    "# Supprimer la colonne 'D-N'\n",
    "TM = TM.drop(\"D-N\")\n",
    "\n",
    "# Renommer les colonnes pour les saisons\n",
    "TM = TM.withColumnRenamed(\"DJF\", \"mean_winter\") \\\n",
    "         .withColumnRenamed(\"MAM\", \"mean_spring\") \\\n",
    "         .withColumnRenamed(\"JJA\", \"mean_summer\") \\\n",
    "         .withColumnRenamed(\"SON\", \"mean_autumn\") \\\n",
    "         .withColumnRenamed(\"J-D\", \"mean_year\")\n",
    "\n",
    "# Supprimer les lignes avec des valeurs nulles\n",
    "TM_cleaned = TM.dropna()\n",
    "\n",
    "# Vérification et suppression des doublons\n",
    "TM_cleaned = TM_cleaned.dropDuplicates()\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "print(\"Données nettoyées:\")\n",
    "TM_cleaned.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7798c15-ee6d-4035-9dc4-d5473de839fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour l'Hémisphère Nord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633ae58-56b9-4df4-a8cf-ff7bf0a2047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_thn = 'THN.csv'  # Remplacez par le chemin correct de votre fichier TM.csv\n",
    "THN = spark.read.csv(path_thn, header=True, inferSchema=True)\n",
    "\n",
    "# Afficher le schéma initial\n",
    "print(\"Schéma initial pour THN:\")\n",
    "THN.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f7195-27bc-408c-9424-4f6af54e7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes des mois en DoubleType\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "for month in months:\n",
    "    THN = THN.withColumn(month, col(month).cast(DoubleType()))\n",
    "\n",
    "# Convertir la colonne 'DJF' en float et remplacer '***' par 0\n",
    "THN = THN.withColumn(\"DJF\", when(col(\"DJF\") == \"***\", 0).otherwise(col(\"DJF\").cast(\"float\")))\n",
    "\n",
    "# Supprimer la colonne 'D-N'\n",
    "THN = THN.drop(\"D-N\")\n",
    "\n",
    "# Renommer les colonnes pour les saisons\n",
    "THN = THN.withColumnRenamed(\"DJF\", \"mean_winter\") \\\n",
    "         .withColumnRenamed(\"MAM\", \"mean_spring\") \\\n",
    "         .withColumnRenamed(\"JJA\", \"mean_summer\") \\\n",
    "         .withColumnRenamed(\"SON\", \"mean_autumn\") \\\n",
    "         .withColumnRenamed(\"J-D\", \"mean_year\")\n",
    "\n",
    "# Supprimer les lignes avec des valeurs nulles\n",
    "THN_cleaned = THN.dropna()\n",
    "\n",
    "# Vérification et suppression des doublons\n",
    "THN_cleaned = THN_cleaned.dropDuplicates()\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "print(\"Données nettoyées:\")\n",
    "THN_cleaned.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a688fc-1736-44c2-919a-075a5f2f7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour l'hémisphère Sud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323bc4f-ef66-4b29-849d-9d6655775cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV\n",
    "path_ths = 'THS.csv'  # Remplacez par le chemin correct de votre fichier TM.csv\n",
    "THS = spark.read.csv(path_ths, header=True, inferSchema=True)\n",
    "\n",
    "# Afficher le schéma initial\n",
    "print(\"Schéma initial pour THS:\")\n",
    "THS.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f218605-79d8-4348-b630-94695a75f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes des mois en DoubleType\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "for month in months:\n",
    "    THS = THS.withColumn(month, col(month).cast(DoubleType()))\n",
    "\n",
    "# Convertir la colonne 'DJF' en float et remplacer '***' par 0\n",
    "THS = THS.withColumn(\"DJF\", when(col(\"DJF\") == \"***\", 0).otherwise(col(\"DJF\").cast(\"float\")))\n",
    "\n",
    "# Supprimer la colonne 'D-N'\n",
    "THS = THS.drop(\"D-N\")\n",
    "\n",
    "# Renommer les colonnes pour les saisons\n",
    "THS = THS.withColumnRenamed(\"DJF\", \"mean_winter\") \\\n",
    "         .withColumnRenamed(\"MAM\", \"mean_spring\") \\\n",
    "         .withColumnRenamed(\"JJA\", \"mean_summer\") \\\n",
    "         .withColumnRenamed(\"SON\", \"mean_autumn\") \\\n",
    "         .withColumnRenamed(\"J-D\", \"mean_year\")\n",
    "\n",
    "# Supprimer les lignes avec des valeurs nulles\n",
    "THS_cleaned = THS.dropna()\n",
    "\n",
    "# Vérification et suppression des doublons\n",
    "THScleaned = THS_cleaned.dropDuplicates()\n",
    "\n",
    "# Afficher les premières lignes pour vérifier\n",
    "print(\"Données nettoyées:\")\n",
    "THS_cleaned.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec8934-7d11-4f91-8984-254f915bd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Stopper la session Spark après l'exécution (optionnel)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5a656-97b3-4757-befa-f7cd01e99dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028d735-f494-4fd6-bcf3-6391937c35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des datasets.\n",
    "datasets = {\n",
    "    \"CO2\": pd.read_csv(r\"C:\\projet\\ficher_traiter_spark\\CO2_cleaned.csv\\CO2.csv\"),  \n",
    "    \"THN\": pd.read_csv(r\"C:\\projet\\ficher_traiter_spark\\THN_cleaned.csv\\THN.csv\"),  \n",
    "    \"THS\": pd.read_csv(r\"C:\\projet\\ficher_traiter_spark\\THS_cleaned.csv\\THS.csv\"),\n",
    "    \"TM\": pd.read_csv(r\"C:\\projet\\ficher_traiter_spark\\TM_cleaned.csv\\TM.csv\"), \n",
    "}\n",
    "# Affichage des premières lignes de chaque dataset.\n",
    "print(\"Dataset CO2:\")\n",
    "print(datasets[\"CO2\"].head(5))\n",
    "print(\"\\nDataset THN:\")\n",
    "print(datasets[\"THN\"].head(5))\n",
    "print(\"\\nDataset THS:\")\n",
    "print(datasets[\"THS\"].head(5))\n",
    "print(\"\\nDataset TM:\")\n",
    "print(datasets[\"TM\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2625a-5716-4331-babf-e10d55c8e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour générer des graphiques interactifs afin de pouvoir augmenter la précision de la visualisation.\n",
    "\n",
    "def generate_graph(dataset_name, variable, graph_type):\n",
    "    df = datasets[dataset_name]  \n",
    "    title = f\"{graph_type} - {variable} ({dataset_name})\"\n",
    "    \n",
    "    if graph_type == \"Line\":\n",
    "        fig = px.line(df, x=\"Year\", y=variable, title=title)\n",
    "        fig.update_layout(xaxis_title='Années', yaxis_title=variable)\n",
    "        fig.update_traces(line_color='#456987')\n",
    "        fig.update_layout(title={\n",
    "            'y': 0.9,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'\n",
    "        })\n",
    "    elif graph_type == \"Bar\":\n",
    "        fig = px.bar(df, x=\"Year\", y=variable, color=variable, title=title)\n",
    "        fig.update_layout(\n",
    "            barmode=\"stack\",\n",
    "            xaxis_title=\"Années\",\n",
    "            yaxis_title=variable\n",
    "        )\n",
    "        fig.layout.coloraxis.colorbar.title = variable\n",
    "        fig.update_layout(title={\n",
    "            'y': 0.9,\n",
    "            'x': 0.4,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'\n",
    "        })\n",
    "    elif graph_type == \"Box\":\n",
    "        fig = px.box(df, y=variable, title=title)\n",
    "        fig.update_layout(\n",
    "            yaxis_title=f\"{variable} (°C)\" if 'Temp' in dataset_name else variable,\n",
    "            title={\n",
    "                'y': 0.9,\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid graph type. Use 'Line' or 'Bar',or Box.\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Interface pour sélectionner les paramètres.\n",
    "dataset_name = input(\"Choisissez un dataset (CO2, THN, THS, THS): \")\n",
    "variable = input(f\"Choisissez une variable à visualiser dans {dataset_name} : \")\n",
    "graph_type = input(\"Choisissez un type de graphique (Line, Bar ou Box) : \")\n",
    "\n",
    "# Génération du graphique.\n",
    "generate_graph(dataset_name, variable, graph_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37d42a-8189-4f0c-92b1-293633ed8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compte tenu de certains résultats obtenus lors de la visualisation (présence d'outliers), une analyse et un traitement plus approfondis sont nécessaires \n",
    "#pour approfondir l'analyse de nos données tout en évitant les biais.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
